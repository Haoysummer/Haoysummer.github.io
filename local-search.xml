<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>机器学习Lab01</title>
    <link href="/2024/04/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Lab01/"/>
    <url>/2024/04/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0Lab01/</url>
    
    <content type="html"><![CDATA[<h2 id="DataSetcar1000"><a href="#DataSetcar1000" class="headerlink" title="DataSetcar1000"></a>DataSet<code>car1000</code></h2><p>这是一个关于汽车测评的数据集，类别变量为汽车的测评，（unacc，ACC，good，vgood）分别代表（不可接受，可接受，好，非常好），而6个属性变量分别为「买入价」，「维护费」，「车门数」，「可容纳人数」，「后备箱大小」，「安全性」。值得一提的是6个属性变量全部是<strong>有序</strong>类别变量：</p><ul><li>buying       v-high, high, med, low</li><li>maint        v-high, high, med, low</li><li>doors        2, 3, 4, 5-more</li><li>persons      2, 4, more</li><li>lug_boot     small, med, big</li><li>safety       low, med, high</li></ul><hr><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>决策树学习通常包括三个步骤：<strong>特征选择</strong>、<strong>决策树的生成</strong>和<strong>决策树的剪枝</strong>。</p><h3 id="算法选择"><a href="#算法选择" class="headerlink" title="算法选择"></a>算法选择</h3><p>常用的决策树算法有：<font color="cornflowerblue">ID3</font>(信息增益)、<font color="cornflowerblue">C4.5</font>(增益率)、<font color="cornflowerblue">CART</font>(基尼系数)，根据小组分工我选择了&#x3D;&#x3D;ID3算法&#x3D;&#x3D;进行划分选择。</p><p>决策树的剪枝算法包括<font color="cornflowerblue">预剪枝</font>和<font color="cornflowerblue">后剪枝</font>。</p><h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h3><p>常用的方法有：<font color="cornflowerblue">留出法</font>、<font color="cornflowerblue">交叉验证法</font>、<font color="cornflowerblue">自助法</font>，实验中优先选择&#x3D;&#x3D;交叉验证法&#x3D;&#x3D;。</p><h3 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h3><hr><h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><h3 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h3><h4 id="处理-txt文件格式的数据集文件"><a href="#处理-txt文件格式的数据集文件" class="headerlink" title="处理.txt文件格式的数据集文件"></a>处理.txt文件格式的数据集文件</h4><blockquote><p>其实不用转换为csv格式也可以，但是不太熟练Python，网上的资源基本都是处理csv……</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入txt数据集，并制定列名</span><br>txtDF = pd.read_csv(<span class="hljs-string">&#x27;D:\\Summer\\HNU\\大三_下\\机器学习\\lab_01\\Lab01\\car1000\\car_1000.txt&#x27;</span>, header=<span class="hljs-literal">None</span>)  <br>columns = [<span class="hljs-string">&#x27;buying&#x27;</span>, <span class="hljs-string">&#x27;maint&#x27;</span>, <span class="hljs-string">&#x27;doors&#x27;</span>, <span class="hljs-string">&#x27;persons&#x27;</span>, <span class="hljs-string">&#x27;lug_boot&#x27;</span>, <span class="hljs-string">&#x27;safety&#x27;</span>, <span class="hljs-string">&#x27;outcome&#x27;</span>]  <br>txtDF.columns = columns  <br>txtDF.to_csv(<span class="hljs-string">&#x27;car_1000.csv&#x27;</span>, index=<span class="hljs-literal">False</span>)  <br><br>data = pd.read_csv(<span class="hljs-string">&#x27;car_1000.csv&#x27;</span>)<br><span class="hljs-comment">#print(data)</span><br><span class="hljs-comment"># 统计每个特征的取值情况</span><br>column_count = <span class="hljs-built_in">dict</span>([(ds, <span class="hljs-built_in">list</span>(pd.unique(data[ds]))) <span class="hljs-keyword">for</span> ds <span class="hljs-keyword">in</span> data.iloc[:, :-<span class="hljs-number">1</span>].columns])<br></code></pre></td></tr></table></figure><ul><li><p>Line10：</p><p><code>for ds in data.iloc[:, :-1].columns</code>：遍历数据集中<font color="cornflowerblue">除最后一列外的所有列</font>(<code>data.iloc[:, :-1]</code>)，获取这些特征的名字</p><p><code>list(pd.unique(data[ds])</code>：将选中列的数据转换为列表，确保它可以被直接用作字典的值</p><p><code>dict()</code>：将特征名和该列的唯一值列表生成一个包含元组的列表，并转换成字典</p></li></ul><h3 id="生成决策树"><a href="#生成决策树" class="headerlink" title="生成决策树"></a>生成决策树</h3><h4 id="计算信息熵"><a href="#计算信息熵" class="headerlink" title="计算信息熵"></a>计算信息熵</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cal_information_entropy</span>(<span class="hljs-params">data</span>):<br>    data_label = data.iloc[:,-<span class="hljs-number">1</span>]<br>    label_class =data_label.value_counts() <span class="hljs-comment">#总共有多少类</span><br>    Ent = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> label_class.keys():<br>        p_k = label_class[k]/<span class="hljs-built_in">len</span>(data_label)<br>        Ent += -p_k*np.log2(p_k)<br>    <span class="hljs-keyword">return</span> Ent<br></code></pre></td></tr></table></figure><ul><li><p>提取最后一列作为标签列<code>data_label</code></p></li><li><p>调用函数<code>value_counts</code>计算每个取值在<code>data_label</code> 中出现的次数</p></li><li><p>for循环遍历标签列：</p><ul><li><p>计算每一种取值所占的比例<code>p_k</code>：该取值出现的次数除以列的总长度</p></li><li><p>根据公式：<br>$$<br>Ent(D)&#x3D;-\sum_{k&#x3D;1}^{|y|}{p_klog_2 p_k}<br>$$<br>计算出信息熵<code>Ent</code></p></li></ul></li></ul><h4 id="计算属性的信息增益"><a href="#计算属性的信息增益" class="headerlink" title="计算属性的信息增益"></a>计算属性的信息增益</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cal_information_gain</span>(<span class="hljs-params">data, a</span>):<br>    Ent = cal_information_entropy(data)<br>    feature_class = data[a].value_counts() <span class="hljs-comment">#特征有多少种可能</span><br>    gain = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> feature_class.keys():<br>        weight = feature_class[v]/data.shape[<span class="hljs-number">0</span>]<br>        Ent_v = cal_information_entropy(data.loc[data[a] == v])<br>        gain += weight*Ent_v<br>    <span class="hljs-keyword">return</span> Ent - gain<br></code></pre></td></tr></table></figure><ul><li><p>信息增益：<br>$$<br>Gain(D,a)&#x3D;Ent(D)-\sum_{v&#x3D;1}^{V}{\frac{|D^v|}{|D|}Ent(D^v)}<br>$$</p></li><li><p>遍历特征a的每种取值v：</p><ul><li>计算取值v在数据集中出现的概率<code>weight</code></li><li>选择取值为 <code>v</code> 的所有行<code>data.loc[data[a] == v]</code> ，计算其信息熵<code>Ent_v</code>后，得到加权信息熵<code>gain</code></li></ul></li></ul><h4 id="获取标签最多的类别"><a href="#获取标签最多的类别" class="headerlink" title="获取标签最多的类别"></a>获取标签最多的类别</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_most_label</span>(<span class="hljs-params">data</span>):<br>    data_label = data.iloc[:,-<span class="hljs-number">1</span>]<br>    label_sort = data_label.value_counts(sort=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> label_sort.keys()[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure><ul><li>计算标签列 <code>data_label</code> 中每个标签的出现次数，设置 <code>sort=True</code> ，确保结果是按降序排列</li><li><code>label_sort.keys()</code>返回Index对象，其中包含了降序排列后的标签，因此<code>label_sort.keys()[0]</code> 是出现次数最多的标签</li></ul><h4 id="挑选最大信息增益特征"><a href="#挑选最大信息增益特征" class="headerlink" title="挑选最大信息增益特征"></a>挑选最大信息增益特征</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_best_feature</span>(<span class="hljs-params">data</span>):<br>    features = data.columns[:-<span class="hljs-number">1</span>]<br>    res = &#123;&#125;<br>    <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> features:<br>        temp = cal_information_gain(data, a)<br>        res[a] = temp<br>    res = <span class="hljs-built_in">sorted</span>(res.items(),key=<span class="hljs-keyword">lambda</span> x:x[<span class="hljs-number">1</span>],reverse=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> res[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure><ul><li>提取所有列名作为特征列</li><li>求各特征的信息增益，并将特征名<code>a</code>和信息增益<code>temp</code>添加到字典<code>res</code>中</li><li>对字典 <code>res</code> 中的键值对进行排序：<ul><li><code>key=lambda x: x[1]</code> 指定每个键值对的第二个元素（即信息增益）为排序的依据</li><li><code>reverse=True</code> 表示按降序排序</li></ul></li><li>返回信息增益最大的特征名</li></ul><h4 id="划分数据集"><a href="#划分数据集" class="headerlink" title="划分数据集"></a>划分数据集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">drop_exist_feature</span>(<span class="hljs-params">data, best_feature</span>):<br>    attr = pd.unique(data[best_feature])<br>    new_data = [(nd, data[data[best_feature] == nd]) <span class="hljs-keyword">for</span> nd <span class="hljs-keyword">in</span> attr]<br>    new_data = [(n[<span class="hljs-number">0</span>], n[<span class="hljs-number">1</span>].drop([best_feature], axis=<span class="hljs-number">1</span>)) <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> new_data]<br>    <span class="hljs-keyword">return</span> new_data<br></code></pre></td></tr></table></figure><ul><li><p>获取最佳特征列<code>data[best_feature]</code>中所有的<strong>唯一值</strong></p><blockquote><p><code>unique()</code>：用于获取一个Series或一维数组中的唯一值，返回一个数组，其中包含输入序列中所有<font color="cornflowerblue">不重复的值</font>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">eg1:Series<br>pd.Series([<span class="hljs-string">&#x27;apple&#x27;</span>, <span class="hljs-string">&#x27;banana&#x27;</span>, <span class="hljs-string">&#x27;apple&#x27;</span>, <span class="hljs-string">&#x27;orange&#x27;</span>, <span class="hljs-string">&#x27;banana&#x27;</span>])  <br>unique_values = s.unique()  <br>&gt;--------------------------------------------------------------<br>&gt;获取Series的唯一值，<br>&gt;此时unique_values = [<span class="hljs-string">&#x27;apple&#x27;</span> <span class="hljs-string">&#x27;banana&#x27;</span> <span class="hljs-string">&#x27;orange&#x27;</span>]<br>&gt;===================================================================<br>eg2:DataFrame<br>df = pd.DataFrame(&#123;  <br>    <span class="hljs-string">&#x27;Fruit&#x27;</span>: [<span class="hljs-string">&#x27;apple&#x27;</span>, <span class="hljs-string">&#x27;banana&#x27;</span>, <span class="hljs-string">&#x27;apple&#x27;</span>, <span class="hljs-string">&#x27;orange&#x27;</span>, <span class="hljs-string">&#x27;banana&#x27;</span>],  <br>    <span class="hljs-string">&#x27;Count&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]  <br>&#125;)   <br>unique_fruits = df[<span class="hljs-string">&#x27;Fruit&#x27;</span>].unique()  <br>&gt;--------------------------------------------------------------<br>&gt;获取<span class="hljs-string">&#x27;Fruit&#x27;</span>列的唯一值，<br>&gt;此时unique_fruits = [<span class="hljs-string">&#x27;apple&#x27;</span> <span class="hljs-string">&#x27;banana&#x27;</span> <span class="hljs-string">&#x27;orange&#x27;</span>]<br></code></pre></td></tr></table></figure></blockquote></li><li><p>根据每个唯一值<code>nd</code>拆分数据集：</p><ul><li>选择数据集<code>data</code>的最佳列<code>best_feature</code>中取值为<code>nd</code>的所有行，创建一个新的元组<code>(nd, ...)</code></li><li>将产生的元组收集到<code>new_data</code>中</li></ul></li><li><p>再次遍历<code>new_data</code>的每个元组，从子集中删除最佳列：</p><ul><li><p><code>n[0]</code>：唯一值</p></li><li><p><code>n[1].drop([best_feature], axis=1)</code>：删去原子集中的最佳列</p><blockquote><p><code>drop()</code> 的参数：</p><ul><li><code>labels</code>：需要删除的行或列的标签，需要删除最佳列，所以传递 <code>best_feature</code> 。</li><li><code>axis</code>：指定删除的维度，0表示删除行，1表示删除列。因为要删除最佳列，所以使用 <code>axis=1</code>。</li></ul></blockquote></li></ul></li></ul><h4 id="创建决策树"><a href="#创建决策树" class="headerlink" title="创建决策树"></a>创建决策树</h4><p>统计每个特征的取值情况作为全局变量<code>column_count</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data = pd.read_csv(<span class="hljs-string">&#x27;car_1000.csv&#x27;</span>)<br>column_count = <span class="hljs-built_in">dict</span>([(ds, <span class="hljs-built_in">list</span>(pd.unique(data[ds]))) <span class="hljs-keyword">for</span> ds <span class="hljs-keyword">in</span> data.iloc[:, :-<span class="hljs-number">1</span>].columns])<br></code></pre></td></tr></table></figure><ul><li>创建一个字典，键是全部属性变量，值是所有的唯一值列表</li></ul><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_tree</span>(<span class="hljs-params">data</span>):<br>    data_label = data.iloc[:,-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(data_label.value_counts()) == <span class="hljs-number">1</span>: <br>        <span class="hljs-keyword">return</span> data_label.values[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">all</span>(<span class="hljs-built_in">len</span>(data[i].value_counts()) == <span class="hljs-number">1</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data.iloc[:,:-<span class="hljs-number">1</span>].columns): <br>        <span class="hljs-keyword">return</span> get_most_label(data)<br>    best_feature = get_best_feature(data) <br>    Tree = &#123;best_feature:&#123;&#125;&#125; <br>    exist_vals = pd.unique(data[best_feature]) <br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(exist_vals) != <span class="hljs-built_in">len</span>(column_count[best_feature]): <br>        no_exist_attr = <span class="hljs-built_in">set</span>(column_count[best_feature]) - <span class="hljs-built_in">set</span>(exist_vals) <br>        <span class="hljs-keyword">for</span> no_feat <span class="hljs-keyword">in</span> no_exist_attr:<br>            Tree[best_feature][no_feat] = get_most_label(data) <br><br>    <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> drop_exist_feature(data,best_feature): <br>        Tree[best_feature][item[<span class="hljs-number">0</span>]] = create_tree(item[<span class="hljs-number">1</span>])<br>    <span class="hljs-keyword">return</span> Tree<br></code></pre></td></tr></table></figure><ul><li><p><code>value_counts()</code> ：用于计算唯一值在 Series 中出现的次数，并按照次数从高到低进行排序：</p></li><li><p>所有样本的<font color="cornflowerblue">标签</font>都相同：直接返回该标签，无须再构建树</p></li><li><p>所有<font color="cornflowerblue">数据的特征值</font>都相同：选样本最多的类作为分类结果</p><blockquote><p><code>all()</code> 是 Python 的一个内置函数，用于判断给定的可迭代对象（如列表、元组、集合、字符串等）中的所有元素是否都为 <code>True</code>(所有非零数字、非空字符串、非空容器等都为<code>True</code>)</p></blockquote></li><li><p>用字典形式存储决策树，将根据信息增益来划分数据集，获取最佳特征的所有唯一值<code>exist_vals</code>：</p><ul><li><p>存在缺失值或异常值(特征的取值与原来的数量不同，即存在异常或缺失)：</p><p>将少的那些特征存储在<code>no_exist_attr</code>中；缺失的特征分类为当前类别最多的</p></li><li><p>根据特征值的不同递归构建子树，最终形成决策树</p></li></ul></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>机器学习</tag>
      
      <tag>决策树</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《你想活出怎样的人生》</title>
    <link href="/2024/04/05/%E3%80%8A%E4%BD%A0%E6%83%B3%E6%B4%BB%E5%87%BA%E6%80%8E%E6%A0%B7%E7%9A%84%E4%BA%BA%E7%94%9F%E3%80%8B/"/>
    <url>/2024/04/05/%E3%80%8A%E4%BD%A0%E6%83%B3%E6%B4%BB%E5%87%BA%E6%80%8E%E6%A0%B7%E7%9A%84%E4%BA%BA%E7%94%9F%E3%80%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="《苍鹭与少年》"><a href="#《苍鹭与少年》" class="headerlink" title="《苍鹭与少年》"></a>《苍鹭与少年》</h1><blockquote><p>2024&#x2F;04&#x2F;04  Thursday  清明  阴雨</p><p>今年的清明节是2024年4月4日星期四，关注米斯达，下次他还会带来更多令人汗流浃背的冷知识~</p></blockquote><h2 id="观前"><a href="#观前" class="headerlink" title="观前"></a>观前</h2><p>看pv里真人在火焰中奔跑的片段，瞬间就心动了，好喜欢那种第一人称视角的奔跑画面。pv里“火焰包围着男孩”的片段真的技术力爆炸，记得以前看过荒木老贼的漫画术中指出 ”<font color="cornflowerblue">画光就要画影，画风就要画火……</font>“(大概是这样)，那种火舌舔舐男孩四肢，火星子漫天飞舞燎到眼睛的感觉真的好舒服啊啊啊~</p><p>其他的倒是没什么特别的感觉，大概应该是一个男孩思念妈妈，来异世界邂逅可爱的女仆装少女与自己和解的浪漫治愈之作(打脸了吗，如打)，总之pv里没有看到特别喜欢的角色~ 想到已经拿了奥斯卡最佳动画长篇，虽然没指望能达到千与千寻的高度，但还是一把子期待了！！</p><h2 id="观看ing"><a href="#观看ing" class="headerlink" title="观看ing"></a>观看ing</h2><p>好困好困……八点半开始的电影，因为想要认真品鉴所以刻意看得非常投入，一直有一种不明觉厉的还在铺垫的感觉，等我觉得“这下铺垫得差不多了吧……”的时候瞄了一眼手机，此时距离电影结束还有十分钟……(ꐦ°᷄д°᷅)？？</p><h2 id="后日谈"><a href="#后日谈" class="headerlink" title="后日谈"></a>后日谈</h2><h4 id="评分：★★★★★★★☆☆☆"><a href="#评分：★★★★★★★☆☆☆" class="headerlink" title="评分：★★★★★★★☆☆☆"></a>评分：★★★★★★★☆☆☆</h4><h3 id="音乐"><a href="#音乐" class="headerlink" title="音乐"></a>音乐</h3><p>音乐大多数都是那种紧迫or诡谲的感觉，确实在男主没有进入塔之前的部分都非常阴森和诡异，有一点点被吓到……后半段感觉印象不深omo</p><p>虽然是和老基友久石让的强强联合，但是其实这次感觉配乐真的没有很抓耳，只能说不突兀，并没能达到和画面天人合一的契合度，有点可惜。</p><h3 id="画面"><a href="#画面" class="headerlink" title="画面"></a>画面</h3><p>顶中顶，背景清新，动画流畅，不过没有那种长得很符合主播xp的角色(((</p><h3 id="隐喻"><a href="#隐喻" class="headerlink" title="隐喻"></a>隐喻</h3><p>我大概看懂了的有：</p><ul><li><p>鹦鹉：一眼军国主义&amp;法西斯</p></li><li><p>鹈鹕：他们的主要想法是“能吃的东西太少了，会饿死”、“必须飞出去”，我想大概是日本对外侵略时的借口，以及被裹挟在其中的日本人民</p><blockquote><p>关于这两个，最后传送塔崩塌之后，关在里面的鹈鹕和鹦鹉都变成可爱的小鸟飞出来，但是还是到处拉屎恶心人，这个隐喻我真的很喜欢，又包含着美好的愿望，又是一种很诙谐的讽刺</p></blockquote></li><li><p>苍鹭：真人的内心，前半段总是在揭穿真人的恶意，后半段帮助真人，不是很肯定喵</p></li><li><p>坍缩的人：在战争中死去的人</p></li></ul><p>不懂的部分：</p><ul><li>哇啦哇啦</li><li>塔本身</li><li>久子夏子姐妹、舅爷</li><li>……</li></ul><h3 id="总体感觉"><a href="#总体感觉" class="headerlink" title="总体感觉"></a>总体感觉</h3><p>上面的隐喻大多数都是回味出来的，看的时候完全没看懂。一遍看完感觉是今敏+庵野秀明，绮丽诡异的梦境世界、接受自己、选择残酷的世界，但是更多的还是茫然，表达有点太意识流了。</p><p>想不明白为什么夏子一定要在塔里生育？为什么真人看到什么都那么淡定？为什么明明没有发生什么深刻的事，真人就和夏子和解了？不懂的问题真的很多很多……</p><h3 id="反战or反战败？"><a href="#反战or反战败？" class="headerlink" title="反战or反战败？"></a>反战or反战败？</h3><p>简单讲讲，电影明显表现出了对日本发动侵略战争的不满与批判，但是对于日本国民受尽战争之苦非常同情，这也许就是个人对于历史的看法的局限性吧……(但我是毫不怀疑宫崎骏的立场的(((壁立千仞</p><h3 id="最后……火美可是能成为我母亲的女人啊！！！"><a href="#最后……火美可是能成为我母亲的女人啊！！！" class="headerlink" title="最后……火美可是能成为我母亲的女人啊！！！"></a>最后……火美可是能成为我母亲的女人啊！！！</h3><p>宫崎骏和夏亚总帅相互理解的世界达成了！！</p>]]></content>
    
    
    
    <tags>
      
      <tag>动画电影</tag>
      
      <tag>宫崎骏</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2024/04/05/hello-world/"/>
    <url>/2024/04/05/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><p>let me kangkang~</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
